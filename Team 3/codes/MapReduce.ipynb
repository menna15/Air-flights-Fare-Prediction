{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uHMh-H0p8nNa",
        "outputId": "d3c45a5a-2aef-4bd6-f6dd-a57b2431ad6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317130 sha256=c77b092cae2dc4d4a9bd871b31c552bd189759a06231f13ab5bb9a099586dd2c\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting mrjob\n",
            "  Downloading mrjob-0.7.4-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.6/439.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.10/dist-packages (from mrjob) (6.0)\n",
            "Installing collected packages: mrjob\n",
            "Successfully installed mrjob-0.7.4\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install mrjob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pcEBSk4G8xxy",
        "outputId": "f9e130e4-bcb6-4220-c518-ee0cc88cce80"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lCPhwTRzvcib",
        "outputId": "84cc94c9-3cf6-4080-f982-38d97f298b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(311807, 13)\n",
            "in 0  the gradients :  [-7062669226.823181, -9305273460.692623, -11253863852.987904, -2778359244.6612897, -7661050811.372348, -5363126236.147571, -1089661184.6847916, -6413608282.132931, -7752376666.287794, -4248654982.895323, -6871328833.009844, -4077866195.523436, -7296390628.805317]\n",
            "in 0  the weights :  [2038.5694705859694, 2685.8749593217412, 3248.316251691286, 801.9458572869361, 2211.286384364246, 1548.0132277771659, 314.51990180009057, 1851.2244610951457, 2237.646682923703, 1226.3321473687133, 1983.3409568526763, 1177.035656780967, 2106.0308381467867]\n",
            "in 1  the gradients :  [-3290234278.3069534, -4218634026.318776, -5618345609.481936, -93280276.82371011, -3672581833.4828944, -2515300348.2431774, -21381762.88422237, -2997321320.043823, -3712000092.9375186, -2230738453.901589, -3098052927.0121484, -1958631031.410076, -3513041762.0614038]\n",
            "in 1  the weights :  [949.7000504064898, 1217.6755115941887, 1621.690190308832, 26.9269992655431, 1060.061436400866, 726.0214791685682, 6.172642626630619, 865.1530274445574, 1071.4392108293257, 643.8844772031749, 894.22863108285, 565.3432086597273, 1014.0114385384693]\n",
            "in 2  the gradients :  [-5311875864.241834, -6952540770.985929, -8637350729.963076, -1554054447.6814785, -5808381067.194587, -4041221219.180971, -606030828.3674856, -4827801092.444548, -5875666266.600814, -3308724270.536043, -5121922795.107766, -3093325734.0027895, -5538553899.827892]\n",
            "in 2  the weights :  [1533.2233640739798, 2006.7858869885702, 2493.0908779689585, 448.5624992971047, 1676.5350236170104, 1166.4607778137326, 174.92481158446196, 1393.4997080663254, 1695.956266001995, 955.0325304843095, 1478.3951155308573, 892.8596259976836, 1598.6519385259114]\n",
            "in 3  the gradients :  [-4227567486.583198, -5485862278.976818, -7017998333.268087, -770126376.3645768, -4662864283.638089, -3222784819.2907686, -292182462.27027786, -3846030738.0946255, -4715204006.697268, -2730594610.008592, -4036373477.2725697, -2484746929.785849, -4452191864.952672]\n",
            "in 3  the weights :  [1220.2503696705073, 1583.4462083718474, 2025.6836539430028, 222.2907838352289, 1345.894935208163, 930.2286356526537, 84.33613270111508, 1110.1231208030106, 1361.0023397775549, 788.1621321307853, 1165.0639381080182, 717.2004366173704, 1285.0861799051302]\n",
            "in 4  the gradients :  [-4809177405.080591, -6272583925.063999, -7886605102.015328, -1190626099.8731825, -5277305519.28349, -3661784836.8248014, -460532652.2103692, -4372640285.384481, -5337661739.8644285, -3040695922.143128, -4618650442.472605, -2811181052.6233735, -5034903488.807742]\n",
            "in 4  the weights :  [1388.1253041388516, 1810.5242560364852, 2276.396889309841, 343.663135463188, 1523.24624729544, 1056.940881836738, 132.92845585591704, 1262.1228381906888, 1540.6675205820854, 877.6692670626818, 1333.131407846753, 811.421847285469, 1453.2791088040892]\n",
            "in 5  the gradients :  [-4497207345.474026, -5850593412.157912, -7420692419.334904, -965073757.2891175, -4947725048.835809, -3426309351.7269435, -370231088.8818872, -4090171910.213234, -5003781298.370092, -2874360502.206648, -4306322538.516718, -2636084877.9728394, -4722342462.633966]\n",
            "in 5  the weights :  [1298.0787769933531, 1688.721605411258, 2141.9166155250864, 278.5600766472723, 1428.1166800022772, 988.9736234154677, 106.86396048782004, 1180.5916289308107, 1444.2968166873384, 829.6584838309126, 1242.9815930941654, 760.882374159024, 1363.0620060363167]\n",
            "in 6  the gradients :  [-4664545188.944468, -6076945221.358228, -7670603664.84636, -1086057947.5315015, -5124508953.336534, -3552616216.710708, -418668011.1069792, -4241685323.9141006, -5182871667.369659, -2963581277.9393315, -4473852327.938676, -2730004840.392908, -4889997296.157193]\n",
            "in 6  the weights :  [1346.3788981125474, 1754.055420961832, 2214.0505881932986, 313.48075520405826, 1479.1432967090798, 1025.4306300935743, 120.84471440214176, 1224.3242125542338, 1495.9891675301901, 855.4110224370321, 1291.3371171784916, 787.9912783155474, 1411.4536226452692]\n",
            "in 7  the gradients :  [-4574786721.491561, -5955532209.391986, -7536553589.977249, -1021163149.570245, -5029683706.338847, -3484866385.584481, -392686895.16794926, -4160414933.8482494, -5086809254.203574, -2915724081.1733894, -4383990902.40478, -2679627043.502721, -4800068798.137236]\n",
            "in 7  the weights :  [1320.4711610487852, 1719.0109680048865, 2175.358594093592, 294.74962698745463, 1451.7730926944967, 1005.8754297794256, 113.34556764225894, 1200.866460248022, 1468.2618698986525, 841.5975995299254, 1265.3996624628294, 773.4503135161276, 1385.4968082370629]\n",
            "in 8  the gradients :  [-4622932331.134758, -6020657023.20978, -7608456807.14836, -1055972117.4581678, -5080547089.547539, -3521206766.7817097, -406622924.8441197, -4204007617.487836, -5138336241.873221, -2941394237.757383, -4432191737.809691, -2706649226.619199, -4848305610.601515]\n",
            "in 8  the weights :  [1334.3678309764991, 1737.808487621664, 2196.1126209544573, 304.7968304780267, 1466.4542163337294, 1016.3646578998665, 117.36804042737468, 1213.4489810695895, 1483.134535242826, 849.0069914907747, 1279.3122726639704, 781.249952201334, 1399.4198027977068]\n",
            "in 9  the gradients :  [-4597107472.55716, -5985724676.953665, -7569888588.187232, -1037300909.8524749, -5053264442.430239, -3501714123.277317, -399147767.7490729, -4180624906.2011228, -5110697643.476403, -2927625003.7947726, -4406337256.645532, -2692154778.1614323, -4822431831.676326]\n",
            "in 9  the weights :  [1326.9137860855446, 1727.7256724009321, 2184.9803533899876, 299.4076036893117, 1458.5793977458422, 1010.7383331984735, 115.21042332422616, 1206.6998335735955, 1475.156975460498, 845.0326623472886, 1271.8496775581386, 777.0662983335238, 1391.9516376177316]\n",
            "in 10  the gradients :  [-4610959687.234646, -6004462063.571857, -7590576223.210395, -1047315972.4815819, -5067898601.36294, -3512169796.5056186, -403157372.70073, -4193167175.7168264, -5125522731.374847, -2935010693.21575, -4420205360.603799, -2699929465.912981, -4836310286.774643]\n",
            "in 10  the weights :  [1330.9120666466893, 1733.134000991445, 2190.951598486528, 302.29833496664946, 1462.803377416358, 1013.7562415976515, 116.3677491316392, 1210.320013708313, 1479.4360645550346, 847.1644556474995, 1275.8525443752687, 779.3103714748759, 1395.957492170976]\n",
            "in 11  the gradients :  [-4603529487.727674, -5994411503.134101, -7579479567.612117, -1041943985.7529784, -5060048974.208096, -3506561470.3372107, -401006657.7841158, -4186439618.6480265, -5117570691.693191, -2931049077.8948703, -4412766638.233934, -2695759195.494602, -4828866012.149239]\n",
            "in 11  the weights :  [1328.767426028143, 1730.2330236847476, 2187.748677985706, 300.7477735140745, 1460.537673888354, 1012.1374635161834, 115.74697029995976, 1208.3781826525258, 1477.1408008429946, 846.0209814885296, 1273.7054437315342, 778.1066714502423, 1393.8087889332942]\n",
            "in 13  the gradients :  [-4605377197.902351, -5996910833.4367, -7582239036.376664, -1043279868.3934637, -5062000985.8529825, -3507956124.856864, -401541488.3536779, -4188112598.7120304, -5119548170.846421, -2932034235.417179, -4414616467.837633, -2696796240.472469, -4830717222.464058]\n",
            "in 13  the weights :  [1329.3007460672882, 1730.9544262905706, 2188.5451665312025, 301.1333604918813, 1461.101099333064, 1012.5400143129527, 115.90134291975909, 1208.8610688786512, 1477.7115771876095, 846.3053357425475, 1274.2393755192013, 778.4060024144652, 1394.343119247158]\n",
            "in 14  the gradients :  [-4606523883.241332, -5998461912.959086, -7583951557.322359, -1044108914.560673, -5063212400.481425, -3508821644.737924, -401873403.16442907, -4189150846.8843346, -5120775390.560949, -2932645622.2585216, -4415764468.490143, -2697439828.567758, -4831866079.983198]\n",
            "in 14  the weights :  [1329.6317234458045, 1731.4021273439787, 2189.0394657726697, 301.37265501999974, 1461.4507600676943, 1012.7898365541103, 115.99714626721509, 1209.1607471309462, 1478.0657998764061, 846.4818054392706, 1274.5707325476606, 778.5917666283971, 1394.6747236001984]\n",
            "in 15  the gradients :  [-4605908811.85826, -5997629928.285812, -7583032976.966608, -1043664221.8839926, -5062562608.907694, -3508357387.899352, -401695367.1376537, -4188593940.1919765, -5120117121.285584, -2932317680.0259633, -4415148691.585091, -2697094613.8811746, -4831249843.462821]\n",
            "in 15  the weights :  [1329.45419024899, 1731.161984650282, 2188.774328242985, 301.2442996539986, 1461.2632052919032, 1012.6558342204575, 115.94575823998531, 1209.0000024952133, 1477.8757981106983, 846.3871487302791, 1274.392995710137, 778.4921244265597, 1394.4968541000603]\n",
            "in 16  the gradients :  [-4606238730.444818, -5998076197.149899, -7583525694.951796, -1043902750.9123096, -5062911151.082585, -3508606410.962695, -401790864.01155937, -4188892659.7777853, -5120470210.821024, -2932493585.198634, -4415478988.607095, -2697279783.8380237, -4831580387.018242]\n",
            "in 16  the weights :  [1329.5494174095636, 1731.2907949644348, 2188.916545555391, 301.31314828213453, 1461.3638079345171, 1012.727711829679, 115.9733223012908, 1209.0862244273, 1477.9777132960141, 846.4379217112695, 1274.4883321016982, 778.5455715796841, 1394.5922616506232]\n",
            "in 17  the gradients :  [-4606061765.174189, -5997836822.669266, -7583261405.593314, -1043774806.1533034, -5062724196.291874, -3508472837.300604, -401739640.3739008, -4188732429.361862, -5120280816.86828, -2932399231.295123, -4415301820.3472185, -2697180460.3901753, -4831403086.52012]\n",
            "in 17  the weights :  [1329.4983384436346, 1731.2217023063267, 2188.84026150774, 301.2762185164078, 1461.3098456098694, 1012.6891573465837, 115.95853719439708, 1209.0399757824296, 1477.9230469356316, 846.4106875550669, 1274.4371945452851, 778.5169030223419, 1394.5410859251795]\n",
            "in 18  the gradients :  [-4606156687.704436, -5997965220.921062, -7583403167.95455, -1043843434.5356549, -5062824477.108046, -3508544484.9743686, -401767116.2581651, -4188818375.471199, -5120382406.028358, -2932449841.854053, -4415396851.759004, -2697233736.5666122, -4831498188.863272]\n",
            "in 18  the weights :  [1329.525736727327, 1731.25876296747, 2188.881179563547, 301.29602730030905, 1461.3387905004367, 1012.7098376138141, 115.96646778863864, 1209.0647831266895, 1477.9523694644417, 846.4252957039205, 1274.4646242563663, 778.5322805706675, 1394.5685361097742]\n",
            "in 19  the gradients :  [-4606105772.139388, -5997896349.289382, -7583327127.938485, -1043806622.9077257, -5062770687.408109, -3508506053.826528, -401752378.44861937, -4188772274.775097, -5120327914.544892, -2932422694.8195386, -4415345877.7909, -2697205159.7195835, -4831447176.848251]\n",
            "in 19  the weights :  [1329.511040542007, 1731.2388839724806, 2188.8592314978277, 301.28540205230354, 1461.323264729529, 1012.6987449102334, 115.96221389142492, 1209.0514766972576, 1477.9366411318854, 846.4174600283321, 1274.4499112136843, 778.5240321963364, 1394.5538120852923]\n"
          ]
        }
      ],
      "source": [
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.regression import LinearRegression\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from sklearn import preprocessing\n",
        "from pyspark.ml.feature import MinMaxScaler\n",
        "\n",
        "# # Create a SparkSession\n",
        "spark = SparkSession.builder.appName(\"MapReduce Linear Regression\").getOrCreate()\n",
        "\n",
        "# # Load the data as a dataframe\n",
        "data = spark.read.csv(\"/content/drive/MyDrive/new.csv\", header=True, inferSchema=True)\n",
        "\n",
        "\n",
        "# Define the input and output columns\n",
        "inputCols = ['Journey_day','Airline', 'Flight_code', 'Class', 'Source', 'Departure', 'Total_stops',\n",
        "       'Arrival', 'Destination', 'Duration_in_hours', 'Days_left',\n",
        "       'Month', 'Day']\n",
        "outputCol = \"Fare\"\n",
        "\n",
        "# Convert the input columns to a vector using VectorAssembler\n",
        "assembler = VectorAssembler(inputCols=inputCols, outputCol=\"features\")\n",
        "data = assembler.transform(data).select(\"features\", outputCol)\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\",min = 0, max = 1)\n",
        "\n",
        "# Compute summary statistics and generate the scaler model\n",
        "scaler_model = scaler.fit(data)\n",
        "\n",
        "# Transform the data using the scaler model\n",
        "data = scaler_model.transform(data).select(\"scaled_features\", outputCol)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "train_data, test_data = data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "sparse_rows = train_data.select(\"scaled_features\").collect()\n",
        "\n",
        "# Convert the list of SparseVector Row objects to a NumPy array\n",
        "sparse_array = np.array([row[0].toArray() for row in sparse_rows])\n",
        "print(sparse_array.shape)\n",
        "\n",
        "# Define the Map function\n",
        "def compute_gradient(data_point, weights):\n",
        "    # Extract the features from the data point as an array\n",
        "    x = np.array(data_point.scaled_features.toArray())\n",
        "    # x = preprocessing.normalize([x])\n",
        "    # # Extract the target variable from the data point\n",
        "    y = np.array(data_point.Fare)\n",
        "    \n",
        "    # # Compute the dot product of the features and weights\n",
        "    dot_product = sum([(x[i]) * weights[i] for i in range(len(x))])\n",
        "    # # Compute the difference between the predicted and actual target variables\n",
        "    error = y - dot_product\n",
        "    # # Compute the gradient of the cost function with respect to the weights\n",
        "    gradient = [-2 * error * x[i] for i in range(len(x))]\n",
        "    # gradient = 2 * np.dot(x.T, error) \n",
        "\n",
        "    return gradient\n",
        "\n",
        "\n",
        "\n",
        "# Define the Reduce function\n",
        "def reduce_gradients(gradient1, gradient2):\n",
        "    return [gradient1[i] + gradient2[i] for i in range(len(gradient1))]\n",
        "\n",
        "# Initialize the weights\n",
        "weights = np.random.randn(13)\n",
        " \n",
        "Partition_data = train_data.repartition(10)\n",
        "\n",
        "# Iterate using MapReduce\n",
        "max_iterations = 20\n",
        "convergence_tolerance = 0.0001\n",
        "for i in range(max_iterations):\n",
        "    gradients = Partition_data.rdd.map(lambda x: compute_gradient(x, weights)).reduce(reduce_gradients)\n",
        "    print(f\"in {i}  the gradients : \" , gradients)\n",
        "    step_size = 0.09\n",
        "    weights = [(weights[i] - step_size * gradients[i])/sparse_array.shape[0] for i in range(len(weights))]\n",
        "    print(f\"in {i}  the weights : \" , weights)\n",
        "    if sum([abs(gradients[i]) for i in range(len(gradients))]) < convergence_tolerance:\n",
        "        break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl-Skrz3SGQ5",
        "outputId": "ae0c59a5-8b95-4635-b0eb-0b20d9db9f6c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 6442.55250893  6741.17507253  6257.88824262 ... 10597.09192985\n",
            "  9274.25113711  8142.57121637]\n",
            "RMSE: 25231.505674820837\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import r2_score,mean_squared_error\n",
        "# Extract the SparseVector column as a list of Row objects\n",
        "sparse_rows = test_data.select(\"scaled_features\").collect()\n",
        "\n",
        "# Convert the list of SparseVector Row objects to a NumPy array\n",
        "sparse_array = np.array([row[0].toArray() for row in sparse_rows])\n",
        "\n",
        "Y_predicted = np.dot(sparse_array,weights)\n",
        "Y_predicted\n",
        "# Print the resulting NumPy array\n",
        "print(abs(Y_predicted))\n",
        "target_rows = test_data.select(\"Fare\").collect()\n",
        "target_rows\n",
        "target_array = np.array([row.Fare for row in target_rows])\n",
        "\n",
        "rmse = np.sqrt(np.mean((target_array - Y_predicted)**2))\n",
        "\n",
        "# Print the RMSE\n",
        "print(\"RMSE:\", rmse)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L0CEpjSWXSAq"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from pyspark.sql import SparkSession\n",
        "\n",
        "\n",
        "def parseVector(line, split):\n",
        "    '''\n",
        "    Input:\n",
        "        - line: String read from a file\n",
        "        - split: Parameter to split the string\n",
        "    \n",
        "    Returns numpy array of each record with float values\n",
        "    '''\n",
        "    return np.array([float(x) for x in line.split(split)])\n",
        "\n",
        "\n",
        "def euclideanDistance(test, train):\n",
        "    '''\n",
        "    Input:\n",
        "        - test: Numpy Array with label as last value\n",
        "        - train: Numpy Array with label as last value\n",
        "    \n",
        "    Returns euclidean distance between test and train arrays\n",
        "    '''\n",
        "    return int(train[-1]), np.sum((test[:-1] - train[:-1]) ** 2)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "\n",
        "    spark = SparkSession.builder.appName(\"Map Reduce KNN\").getOrCreate()\n",
        "\n",
        "    sc = spark.sparkContext\n",
        "    sc.setLogLevel(\"ERROR\")\n",
        "\n",
        "    input_file = spark.read.csv(\"/content/drive/MyDrive/Normalized_data.csv\", header=True, inferSchema=True)\n",
        "    input_data = input_file.rdd.map(lambda x: np.array(x))\n",
        "\n",
        "    # Split data into training and testing sets\n",
        "    training_data, test_data = input_data.randomSplit([0.99, 0.01], seed=47)\n",
        "\n",
        "    K = 1\n",
        "\n",
        "    start_time = time.time()\n",
        "\n",
        "    predict_labels = []\n",
        "    true_labels=[]\n",
        "    for test_point in test_data.collect():\n",
        "        \n",
        "        true_label = int(test_point[-1])\n",
        "\n",
        "        distances = training_data.map(\n",
        "            lambda train_point: euclideanDistance(test_point, train_point))\n",
        "\n",
        "        k_nearest_neighbours = sc.parallelize(\n",
        "            distances.takeOrdered(K, key = lambda p: p[1])).map(\n",
        "                lambda x: (x[0], 1))\n",
        "\n",
        "        k_nearest_predictions = k_nearest_neighbours.reduceByKey(\n",
        "            lambda x1, x2: x1 + x2)\n",
        "\n",
        "        predict_label = k_nearest_predictions.takeOrdered(1,\n",
        "            key = lambda x: -x[1])[0][0]\n",
        "\n",
        "        predict_labels.append(predict_label)\n",
        "        true_labels.append(true_label)\n",
        "\n",
        "    end_time = time.time()\n",
        "    RMSE=np.sqrt(np.mean((true_labels-predict_labels)**2))\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    print (\"\\nRMSE: \" + str(RMSE) + \"%\\n\")\n",
        "    print (\"\\nTime taken: \" + str(time_taken) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xpFvubKHXUnf",
        "outputId": "6974a235-20bb-4d82-9815-4531b17c074a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "712\n",
            "\n",
            "RMSE: 176406.579035477%\n",
            "\n",
            "\n",
            "Time taken: 10193.650690793991\n",
            "\n"
          ]
        }
      ],
      "source": [
        "    end_time = time.time()\n",
        "    print(len(predict_labels))\n",
        "    error = 0\n",
        "    for i in range(len(predict_labels)):\n",
        "       error += (true_labels[i]-predict_labels[i])**2\n",
        "    RMSE=np.sqrt(np.mean(error))\n",
        "    time_taken = end_time - start_time\n",
        "\n",
        "    print (\"\\nRMSE: \" + str(RMSE) + \"%\\n\")\n",
        "    print (\"\\nTime taken: \" + str(time_taken) + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.8.5 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5"
    },
    "vscode": {
      "interpreter": {
        "hash": "7d59387d170154bb3d5dc622ecb4d30c82e484fcbe8f0ac5a8bf3d702f022ce7"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
